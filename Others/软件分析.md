[课程主页](https://tai-e.pascal-lab.net/lectures.html)

[参考笔记](https://static-analysis.cuijiacai.com/)

# Lec 1: Introduction
### 为什么需要静态分析？
+ 程序的可靠性：
  + 空指针解引用
  + 内存泄漏
+ 程序的安全性：
  + 隐私信息泄露
  + 注入攻击
+ 编译优化：
  + 死代码消除
  + 代码移动：
    + > 将一个计算移动到相比原来位置执行得不那么频繁的位置上，可以减少运行程序执行的总操作数。因为相对于包围循环的代码来说，循环本身倾向于执行多得多的次数，所以此领域的大部分工作都专注于将不变的表达式从循环中移出。该变换插入代码以使这些操作在所有代码路径上都变成冗余的，并删除这些新的冗余表达式。
+ 程序理解：
  + 编译器如何实现找到调用关系、类型推断等功能

静态分析在运行程序之前，分析出程序的一些特性：
+ 隐私信息泄露？
+ 空指针解引用？
+ 类型转换cast操作是否安全？
+ 两个指针指向同一块内存空间吗？
+ 某个特定的assert会失败吗？
+ 某一块代码块是死代码吗？

### Sound and Safe
**莱斯定理：递归可枚举语言的所有非平凡（nontrival）性质都是不可判定的。**

“平凡” == 一个性质被所有语言满足 or 所有语言都不满足

莱斯定理意味着不存在“完美的”静态分析，也即不能对程序P的一个非平凡特性给出确切的答案。

只有：**Sound > Truth > Safe**。其中：
+ Sound：过近似，Overapproximate，包含了一切事实及真相之外的东西，有一个真子集是真相
+ Safe：欠近似，Underapproximate，真相的真子集

不存在Sound and Complete的分析，因此需要向其中一个妥协：
+ 妥协 Soundness：存在FN，未找到的真相
+ 妥协 Completeness：存在FP，把非真相当作真相：更多的选择，因为我们希望找到程序中的一切漏洞，故而允许多报错，不容忍漏报。

现实中的静态分析：尽量接近soundness，并且在分析精度和速度之间做权衡。

### Abstraction
用两个词语概括静态分析：抽象、过近似。

抽象：根据具体分析的问题，忽略一些细节。例如，把所有数字划分为五类：
+ 正数
+ 负数
+ 零
+ 未确定
+ 未定义

过近似：使用状态转移函数。

# Lec 2：IR-Intermediate Representation
### 编译器和静态分析器
编译器将程序从源代码转换为机器码，经历以下步骤：
+ 扫描器Scanner：进行词法分析Lexical analysis，结果为一个token串
+ 解析器Parser：语法分析Syntax analysis，分析上下文无关的语法，结果为一个抽象语法树AST
+ 类型检查器Type Checker：语义分析Semantic analysis，输出Decorated AST
+ 翻译器Translator：将Decorated AST翻译为中间表示IR
+ 机器码生成器：将IR翻译为机器码

其中，静态分析器使用生成的中间表示IR。

IR与AST对比：
+ IR：
  + 层次低，靠近机器码
  + 语言无关，和机器相关
  + 包含控制流信息
  + 适合通用的静态分析
+ AST：
  + 高层次，靠近编程语言
  + 依赖于具体编程语言
  + 不包含控制流信息
  + 适合做快速的类型检查



常用IR：三地址码。意思是最多包含三个地址，形如a=b+c。这里的地址具体为：
+ 变量名
+ 标签名：用于指示跳转位置
+ 常量
+ 编译器生成的临时量

还包含一些操作符：
+ 双目操作符：算术运算符、逻辑运算符
+ 单目操作符：取负、按位取反、类型转换
+ 关系运算符：结果为bool值
+ 跳转指令

另一种IR：SSA静态单赋值表示，每次赋值都会创建一个新的变量，每个变量都只有唯一一次定义。
+ 好处：变量名隐含控制流信息；定义和使用的关系明确
+ 坏处：引入过多的变量；需要执行很多的汇合操作（明明是同一个变量，在不同的控制流有着不同的名称，还需要汇合操作并赋值给新的变量）；翻译为机器码效率低（有太多没必要的赋值操作）

Java 3AC in class:
1. invokespecial
2. invokevirtual
3. invokeinterface
4. invokestatic
5. invokedynamic

src to 3AC process: all 语法糖被展开为正经的语言grammar(e.g. string + to string.append() method)

### 控制流分析 CFA: control flow analysis
BB: basic block，最大顺序执行的三地址码指令集合。

intuition：跳转语句的目的地一定是BB的开端、跳转语句本身一定是BB的结尾。

核心是抓住跳转语句。找到所有跳转语句的目的地和跳转语句的下一句，这些是BB的开头。所有跳转语句对应一个BB之间的边；然后还要加上顺序执行的边。最后加入entry和exit块。

note：跳转的目标从指令的标签改为BB的标签，以防指令经常变化，导致跳转目的地的地址（标签）经常变化。

# Lec 3 & 4: Data Flow Analysis — Applications
不同的数据流分析有着不同的：
+ Data：abstraction
+ Flow：safe-approximate 策略
  + may analysis：输出可能为真->soundness
  + must analysis：输出必然为真->safeness
+ CFG->Node：转换函数
+ CFG->Edge：控制流处理

一个IR语句的执行会把input改变为对应的output。定义每两个语句之间为一个程序点Program Point。程序点关联一个数据流值，对应所有可能的程序状态的抽象的集合。

数据流分析就是：在安全的近似下，计算每一个s相应的IN[]和OUT[]。这里安全的近似有如下限制：
+ 语句的语义限制：状态转移函数
  + 正向分析OUT[]=f(IN[])、反向分析IN=f(OUT[])
+ 控制流信息
  + 如果一个BB有多个前驱，则应当使用汇聚操作

### 定义可达性分析 Reaching Definitions Analysis
本分析不考虑方法调用和别名。

对变量v的一个定义，就是一条给v赋值的语句。如果存在一个路径，其上没有把对v的定义覆盖（kill）掉，则认为该定义可达。定义可达性分析，分析每个程序点能够到达的定义。

应用：可以用来分析未定义变量。给每个变量一个伪（dummy）定义，如果在使用时这个定义可达，则认为其没有在使用之前被定义。

因为全集确定，所以使用位向量来抽象表示程序的状态。

+ gen包含这个BB中所有定义语句
+ kill的不止是这个BB的in-edge所连接的BB，而是所有BB中的definition

使用正向分析：
+ 状态转移方程：$OUT[B]=gen_B\cup(IN[B]-kill_B)$。
+ 控制流：$IN[B]=\cup_{P-a-pred-of-B}OUT[P]$。

为什么只初始化OUT呢？其实每一个程序点分别对应一个IN和一个OUT，而且这两者是一样的。所以只需要初始化一个就行。但是正向的分析，entry块比较重要，他是起源；他只有OUT。

可达性分析是单调递增有上界的，因此算法肯定会停止。IN的值依赖于OUT，只要OUT不变，IN肯定也不会变。所以停止条件是任意OUT都没有变化。同理，IN不变则OUT也不会变。

该算法是一个模板entry和其他BB是分开初始化的。在本算法中一起初始化也可以，但是有些特定的其他算法也许必须要分开初始化。

### 活跃变量分析 Live Variables Analysis
分析程序点p处某变量v的值是否会在以p为起点的接下来路径上某处用到，如果用到则称之为活跃变量。反之为死变量。总的来说，分析各个程序点上各变量是死是活。

应用：寄存器分配、编译优化，将新的值覆盖掉死变量寄存器。

使用反向的分析：
+ 状态转移方程：$IN[B]=use_B\cup(OUT[B]-def_B)$。
+ 控制流：$OUT[B]=\cup_{S-a-succ-of-B}IN[S]$。

仅当IN产生变化才会停止。因为自下而上分析。

细节：对于以下BB：
+ BB1：
  + v = 2
  + k = v
  + 这个BB的use集合没有v，def有v，因为用了自己定义的v，而不是别人定义的
+ BB2：
  + k = v
  + v = 2
  + 这个BB的use和def集合都有v

其实这些use、def、kill、gen的细节可以将BB拆分成基本的语句来逐句分析。注意这里是反向分析！！！

### 可用表达式分析 Available Expressions Analysis
分析：所有从程序入口到程序点p，都经过了evaluation of某个表达式，并且在最后一次evaluation之后没有重定义。

应用：公共子表达式消除，减少重复计算。

这是一个正向分析，且是must-analysis。因为这种优化是不能出错的。

定义：
+ gen：这个BB中出现的表达式
+ kill：这个BB中重定义的变量所在的所有表达式

使用正向分析：
+ 状态转移方程：$OUT[B]=gen_B\cup(IN[B]-kill_B)$。
+ 控制流：$IN[B]=\cap_{P-a-pred-of-B}OUT[P]$。

note：在相同的BB中，如果kill之后又gen了，是算gen的。这是因为即使不同的分支里面相同表达式的值不同，真正动态运行时只会取其中一个值。（PPT 242页）

此处的初始化：
+ OUT[entry] = 空集
+ OUT[其他BB] = 全集

note：为了safe，初始化为全集（位向量全为1），因为在取交集的时候如果初始化为全0，则不会产生变化，算法出错；在sound中，初始化为空集。

# Lec 5 & 6：Data Flow Analysis — Foundations
### 重新审视DFA迭代算法
将每一个OUT[B]视为域V中的元素。则每次迭代结束之后的所有输出为一个元组，其中共有k个元素，每个元素代表一个结点的OUT。（k为CFG中总的节点个数）

每一轮迭代更新这个元组并输出，如果两轮迭代的输出一样则可以停止。也即迭代算法达到了不动点。

问题：
+ 能到达不动点吗？
+ 只有一个不动点吗？
+ 如果有多个，能找到最佳不动点吗？
+ 什么时候到达不动点？

### 数学基础
偏序关系，满足如下关系：自反性、反对称性、传递性。偏序集中可能存在两两不可比的元素。如果任意两个元素都可比，则为全序关系（全序集）。

偏序集中的上下界。最小上界（a join b，并集）、最大下界（a meet b，交集）。不是所有偏序集都有最大下界和最小上界，但是如果有，就是唯一的。

+ 格：偏序集中每一对元素都存在最小上界和最大下界。
+ 半格：偏序集中每一对元素只有最小上界和最大下界二者之一。
+ 全格：偏序集中每一个子集都有最小上界和最大下界。

每一个全格都有一个最大的元素和最小的元素，称为top和bottom。每一个有限格都是全格。

给定一系列格，可以定义积格。

+ 单调性：如果定义一个从格映射到格的函数f，称f是单调的，if `x<y` 能推出 `f(x) < f(y)`。
+ 不动点：称`f(x)=x`为函数f的不动点。
+ 格的高度：从底部到顶部的最长路径。

不动点定理。

交汇（交集，meet）和联合（并集，join）操作是单调的。

### 基于格的DFA框架
DFA框架：(D,L,F)
+ D：数据流的方向
+ L：格，包含V的幂集（全格）以及一个集合操作（交汇或者联合）
+ F：一族V到V的转移函数（单调的gen/kill，单调的交汇/联合）

最坏时间复杂度为kh+1 --> O(kh)

### 格视角下的may和must分析
may分析从bottom出发，越过truth（由莱斯定理，不可能停在这里），达到一个不动点；must分析从top出发，越过truth达到一个不动点。

出发点是safe的，越过truth变为sound。

正是由于转移方程和控制流约束函数设计的合理，最小/最大不动点才会包含了truth。如果设计不合理，也可能不包含truth，算法出错。

### 算法精度分析
MOP：Meet Over all Path，计算多条路径的数据流值在汇合点的最小上界或者最大下界。

由于并不是每一条路径都会被执行（精度低），并且同时考虑所有的路径也是不现实的（路径大小是unbounded，比如出现循环；不可枚举的，大程序里路径数太多了！），因此在实际中并不使用MOP算法。但是可以将MOP算法作为衡量其他算法的标尺。

迭代算法和MOP对比：如果转移函数满足分配律，则两者精度一样，而迭代算法复杂度更低；如果不满足分配律，MOP精度更高。

### 常量传播 Constant Propagation
在程序点p给定一个变量x，分析此时变量是否是一个常量。

应用：如果我们知道了某些程序点处的某些变量一定是一个常量的话，我们就可以直接将这个变量视为常量，从而减少内存的消耗（可以在编译的时候就完成一部分计算，并且有些常量并不需要分配储存它的内存空间）。

使用(D,L,F)分析常量传播。
+ D：forward
+ L：
  + UNDEF -> const -> NAC
  + 交汇操作（must analysis）
+ F：$OUT[s]=gen\cup(IN[s]-{(x,\_)})$
  + s: x=const  ->  gen={(x,const)}
  + s: x=y      ->  gen={(x,val(y))}
  + s: x=y op z ->  gen={(x,f(y,z))}
  + 其中，f(y,z)=
    + if val(y) and val(z) are const  -> val(y) op val(z)
    + if val(y) or val(z) is NAC      -> NAC
    + otherwise                       -> UNDEF
  + s: 不是赋值语句 -> F是恒等映射

常量传播不满足分配律，因此算法精度不如MOP。

### 工作表算法 Worklist
工作表算法是对迭代算法的优化，用一个集合储存下一次遍历会发生变化的BB，这样已经达到不动点的基块就可以不用重复遍历了。*Worklist最好采用去重的集合实现，不然可能有重复的BB。*

算法的最后一行只将输出状态发生变化的基块的后继，也就是在下一轮当中输入状态会发生变化的基块加入工作表，由于gen/kill提前计算好不会变，只有当输入状态发生变化时，输出状态才会发生变化。

这个算法本质上是图的广度优先遍历算法的变体，只是加入了一些剪枝的逻辑，每一轮只遍历可能会发生变化的结点，不发生变化的结点提前从遍历逻辑中去除。

# Lec 7：Interprocedural Analysis
为了实现更高的精度，需要过程间分析。这就需要构建调用图，并在其中加入调用边和返回边。

### 调用图构建
调用图就是一个所有从调用点callsite到被调用者callee的边的集合。

调用图的作用：
+ 过程间分析的基础
+ 程序优化、理解、测试、调试（debug）

调用图构建的常用方法：（自上而下的精度提升，效率下降。）
+ 类层级结构 CHA
+ 快速类型分析 RTA
+ 变量类型分析 VTA
+ 指针分析 k-CFA

JAVA中的方法调用有：
+ 静态调用 invokestatic：调用静态方法
+ 特殊调用 invokespecial：调用构造函数、私有实例方法、基类实例方法
+ 虚调用 invokeinterface、invokevirtual：其他实例方法。运行时才确定，因此是调用图构建的关键。

**虚调用的方法派发。**
+ 方法的描述符：返回类型+形参类型
+ 方法的签名：所在类名+方法名+描述符。签名可以作为方法的标识符。
  + <C: T foo(P, Q, R)>
  + 简写为C.foo(P, Q, R)

对于某个形如o.foo()的调用点，记接收对象的类型为c，方法签名为m，定义在运行时刻解析调用点所调用的目标方法的过程为方法派发（Method Dispatch），记为**Dispatch(c,m)**。

note：如果C继承B继承A，其中A和C都有foo()方法，声明`A t = new C()`，程序中调用`t.foo()`，则签名为`A.foo()`，方法派发调用`Dispatch(C,A.foo())`。

Dispatch(c,m)=
+ m'：如果m'是c类中一个非抽象方法，且和m有相同的名字和描述符
+ Dispatch(c',m)：otherwise，这里c'是c的superclass

大多数时候由于控制流的作用，一个调用点可能有不止一种可能的接受对象类型。

**Class Hierarchy Analysis**。
+ 需要知道程序中类之间的继承关系。
+ 根据调用点处接收变量的声明类型来解析虚调用。
+ 假设声明为A类的变量a可能指向A及其所有子类。

定义方法 **Resolve(cs)** 通过CHA找到所有可能的目标方法调用。

note：如果C继承B继承A，其中A和C都有foo()方法，`Resolve(b.foo())`的结果是`{A.foo(),C.foo()}`，这是因为对B类本身的方法派发Dispatch得到的是A类。此时如果是`B b = new B()`，则只可能调用A.foo()，则C.foo()就是不精确的结果。

CHA特点：
+ 优点：快
  + 只考虑了调用点处接收对象的声明类型及其继承结构
  + 忽略数据流和控制流信息
+ 缺点：不精确
  + 很容易引入虚假的目标方法

应用：在IDE中帮助程序员查看调用点处可能的目标方法，因为IDE只是给程序员一个提示，所以只需要保证不发生错误，对于精确性要求不高。

**用CHA构造调用图。**
+ 从entry方法开始
+ 对每个WL中的m，如果m原本不在RM中，T=resolve(cs for cs in m)
  + 将T中的每个m'加入到WL；
  + 在调用图中加入cs -> m'的边
+ 重复直到WL为空

构造完调用图之后发现不可达的代码就是死代码。

### ICFG：过程间控制流图
ICFG=所有CFG+调用边+返回边（从调用图得到这个信息）。

除了调用边和返回边之外，从调用点到紧接着的返回点也有一个“call-to-return edge”，这是包含在普通的CFG中的。控制流并不会从这条边走，但是我们的图中需要这条边，因为有一些信息没必要进入方法体的内部（参数以外的其他变量的信息），可以直接从外面的这条边传递，能够提高效率。
>常量传播问题当中，一个调用点处一般只有接收方法调用返回值的那个变量会发生变化，除此之外的本地变量并不会发生变化，我们可以将这些本地变量沿着调用-返回边传递到下一个结点，方法调用的返回值则由返回边传递。

### 过程间数据流分析
基于ICFG分析。

这里面有多种转移函数（以过程间常量传播为例）：
+ 边转移：
  + 普通边转移：恒等
  + 调用-to-返回边转移：删除LHS（也就是调用方法要return的值，防止两个不同的值汇合变为NAC，提升精度）
  + 调用边转移：传参
  + 返回边转移：传递返回值
+ 节点转移：
  + 调用结点转移：恒等映射
  + 其他结点转移：和普通的过程内一样

# Lec 8：Pointer Analysis
### Motivation
CHA只考虑类的层级结构，在resolve的时候会选择其所有子类，显然不准确；需要指针分析，根据指向关系精确定位。

### 介绍
对于一般的静态分析，指针分析尝试回答每一个指针可能指向哪些内存区域；对于JAVA这种OO语言来说，尝试分析指针（变量variable和域field）指向哪些对象object。*总之，指针分析以程序为输入，输出指向关系。*

指针分析和别名分析很接近，别名关系是可以从指针分析结果中推导得到的。

应用：
+ 其他静态分析的基础
  + 别名分析、调用图
+ 编译器优化
+ 错误检测
  + 空指针检测
+ 安全分析
  + 信息流分析（隐私泄露）

### 指针分析的关键因素
关键因素影响指针分析的精度和效率。
+ 堆抽象：如何建模堆内存？
  + 分配点
  + 无储存
+ 上下文敏感性：如何对调用语境建模？
  + 上下文敏感
  + 不敏感
+ 流敏感性：如何对控制流建模？
  + 流敏感
  + 流不敏感
+ 分析范围：程序的哪个范围要被分析？
  + 全程序
  + 需求驱动

**堆抽象**：由于循环递归等原因，动态运行时的堆区对象数目是unbounded的，而静态分析的堆抽象就是要把动态分配的、无界的堆区对象建模成有界的抽象对象（为了确保程序终止）。

我们使用最常用的分配点抽象。毕竟在程序中，分配点（new语句）肯定是有限的，这里将一个循环中不断分配的堆区对象全部抽象为同一个。

**上下文敏感性**：是否区分同一个方法的不同调用语境。上下文不敏感的话，所有调用放在一起分析，一个方法只分析一次，速度快但是交汇操作损失精度。

**流敏感性**：是否尊重程序语句的执行顺序，还是仅仅将程序视为语句的无序集合。
+ 流敏感的为每个程序点都维护一个指向关系表
+ 流不敏感的只维护一个全局的指向关系表

指针分析中采用流不敏感的方式，代价低，精度可以接受。

**分析范围**：选择全局分析。

### 指针分析关心的语句
显然只关心影响指针的语句。
+ new: A x = new A()
+ assign: x = y
+ store: x.f = y
+ load: y = x.f
+ call: r = x.k(a,b,...)
  + static call
  + special call
  + virtual call

以上语句足以包含所有的指针操作。如果有更复杂的操作，在三地址码中肯定可以转换为上述操作的组合。

JAVA中的指针：
+ 局部变量：x
+ 静态域：C.f
+ 实例域：x.f：建模为x所指向的对象的f域
+ 数组元素：array[i]：忽略下标，建模为一个只有一个域的对象

# Lec 9 & 10：Pointer Analysis — Foundations
### 指针分析的规则
首先考虑前四个影响指针的语句，先不管call语句。

note：$pt(x)$代表指针$x$的指向集合。

rules（前提 ---> 结论）：
+ new: 
  + x = new T()
  + unconditional ---> $o_i\in pt(x)$
+ assign: 
  + x = y
  + $o_i\in pt(y)$ ---> $o_i\in pt(x)$
+ store:
  + x.f = y
  + $o_i\in pt(x), o_j\in pt(y)$ ---> $o_j\in pt(o_i.f)$
+ load:
  + y = x.f
  + $o_i\in pt(x), o_j\in pt(o_i.f)$ ---> $o_j\in pt(y)$

### 如何实现指针分析
本质上指针分析是在**传播**指向信息。就是说如果pt(x)更新了，那么就要把变化的部分传播给和x相关的指针。所以要：
+ 用一个图PFG把指针的关系表示出来
+ 当pt(x)变化了，要把变化的delta传播给x的后继

PFG中的边：
+ x=y: y -> x
+ x.f=y: y -> o_i.f
+ y=x.f: o_i.f -> y

构造好了PFG，则指针分析就可以用在PFG上计算传递闭包的方式来解。实际上，构建PFG和传播是同时进行的。
> 一个指针是没有字段的，当我们通过指针来访问字段的时候，其实访问的是指针指向的对象的字段，也就是说构建PFG时也要用到指向信息。而传递指向信息显然又需要指针流图。

### 指针分析算法
WorkList中的每个entry都是(n,pts)，其中pts是需要被传播给pt(n)的，也即加给n所指向的对象集合。

**Main Algorithm**
```
Solve(S)
  WL = []
  PFG = {}
  foreach i: x = new T() in S do
    add (x, {o_i}) to WL
  foreach x = y in S do
    AddEdge(y, x)

  while WL is not empty do
    remove (n, pts) from WL
    delta = pts - pt(n)
    Propagate(n,delta)
    if n represent a variable x then
      foreach o_i in delta do
        foreach x.f = y in S do
          AddEdge(y, o_i.f)
        foreach y = x.f in S do
          AddEdge(o_i.f, y)
```
note：这里只处理了instance的store和load语句，还有array的；此外还有call语句。

只传播delta：differential propagation，为了防止重复的传播。实际中的delta相比已有的指向集合要小很多，可以提高效率。除此之外，delta在处理存储、载入以及调用语句的时候对于效率的提升也很有作用。

**AddEdge**
```
AddEdge(s, t)
  if s->t not in PFG then
    add s->t to PFG
    if pt(s) is not empty then
      add (t, pt(s)) to WL
```

**Propagete**
```
Propagate(n, pts)
  if pts is not empty then
    pt(n) ∪= pts
    foreach n->s in PFG do
      add (s, pts) to WL
```

### 带有方法调用的指针分析
过程间指针分析需要调用图，但是不能用CHA了，太不精确。现在使用pt(x)来构建调用图，所以是即时的（on-the-fly）调用图构造。

**调用语句规则**
+ l: r = x.k(a1,a2,...,an)
+ $o_i\in pt(x), m=Dispatch(o_i,k), o_u\in pt(a_j), o_v\in pt(m_{ret})$ ---> $o_i\in pt(m_{this}), o_u\in pt(m_{p_j}), o_v\in pt(r)$

其中，方法派发Dispatch对于o_i来说是绝对精确的，误差来源于pt(x)可能包含多个对象。

不能把x->this作为一条PFG边，这是因为接收对象只能流到对应目标方法的this变量中。如果建立了这一条PFG边，则会带来错误的数据流。

调用图构建和过程间指针分析同时进行。一开始RM只有入口方法entry，然后一步步扩展RM。

**Main Algorithm**
```
Solve(S)
  WL = []
  PFG = {}
  S = {}, RM = {}, CG = {}
  AddReachable(m_entry)

  while WL is not empty do
    remove (n, pts) from WL
    delta = pts - pt(n)
    Propagate(n,delta)
    if n represent a variable x then
      foreach o_i in delta do
        foreach x.f = y in S do
          AddEdge(y, o_i.f)
        foreach y = x.f in S do
          AddEdge(o_i.f, y)
        ProcessCall(x, o_i)
```

**AddReachable**
一开始为了入口方法调用一次；在发现了新的调用边的时候调用。
```
AddReachable(m)
  if m not in RM then
    add m to RM
    S ∪= S_m
    foreach i: x = new T() in S_m do
      add (x, {o_i}) to WL
    foreach i: x = y in S_m do
      AddEdge(y, x)
```
如果发现了新的new和assign语句，相当于要补充一些初始化步骤。

**ProcessCall**
```
ProcessCall(x, o_i)
  foreach l: r = x.k(a1,...,an) in S do
    m = Dispatch(o_i, k)
    add (m_this, {o_i}) to WL
    if l->m not in CG then
      add l->m to CG
      AddReachable(m)
      foreach parameter p_i of m do
        AddEdge(a_i, p_i)
      AddEdge(m_ret, r)
```

# Lec 11 & 12：Pointer Analysis — Context Sensitivity
### 上下文敏感的指针分析简介
上下文不敏感指针分析的问题：由于不区分上下文导致对所有调用的数据流都汇合到了同一处。在不同语境下对同一个方法的调用，使得同一个变量指向了不同的对象，相当于不同的上下文被汇聚在一起，造成虚假的数据流。

使用上下文敏感的分析即可解决这个问题。这里采用基于克隆的上下文敏感方法，即每个方法和变量都被一个或者多个上下文所修饰（其中变量的上下文来自于其定义的方法上下文），本质上来说就相当于每个方法和变量都在不同的上下文中生成了一份克隆。

**上下文敏感的堆。**用上下文修饰通过分配点进行抽象的对象，细化堆内存抽象的粒度，提升分析精度。并且OO语言本身就是堆密集型的，需要做这样的细化。最普遍的方法是继承堆对象所在的方法的上下文作为自己的堆上下文。

堆上下文提升精度原因；
+ 动态执行过程中一个分配点可以new多个不同的对象
+ 不同的对象可能处理不同的数据流
+ 不带上下文区分的话，不同的数据流会汇合到一起造成精度损失

单纯的堆上下文也不能提升精度，必须和方法、变量的上下文敏感结合起来使用。

### 上下文敏感的指针分析规则
上下文用来修饰方法、变量、对象、实例域。其规则和上下文不敏感的很相似，如果去掉所有上下文则一模一样。

rules（前提 ---> 结论）：
+ new: 
  + x = new T()
  + unconditional ---> $c:o_i\in pt(c:x)$
+ assign: 
  + x = y
  + $c':o_i\in pt(c:y)$ ---> $c':o_i\in pt(c:x)$
+ store:
  + x.f = y
  + $c':o_i\in pt(c:x), c'':o_j\in pt(c:y)$ ---> $c'':o_j\in pt(c':o_i.f)$
+ load:
  + y = x.f
  + $c':o_i\in pt(c:x), c'':o_j\in pt(c':o_i.f)$ ---> $c'':o_j\in pt(c:y)$
+ call:
  + l: r = x.k(a1,...,an)
  + $c':o_i\in pt(c:x), m=Dispatch(o_i,k), c^t=Select(c,l,c':o_i), c'':o_u\in pt(c:a_j), c''':o_v\in pt(c^t:m_{ret})$ ---> $c':o_i\in pt(c^t:m_{this}), c'':o_u\in pt(c^t:m_{p_j}), c''':o_v\in pt(c:r)$

其中，Dispatch仅仅根据o_i的类别来进行解析，不需要上下文信息；Select是用来给调用的目标方法m（调用的不是方法k，而是解析出来的方法m）选择上下文的。

### 上下文敏感的指针分析算法
实现思路：和上下文非敏感类似，同时构造CSPFG和CS的指向集合传播。

CSPFG中的边：
+ x=y: $c:y \to c:x$
+ x.f=y: $c:y \to c':o_i.f$
+ y=x.f: $c':o_i.f \to c:y$
+ r=x.foo(a1,...,an):
  + $c:a1 \to c^t:m_{pi}$
  + $c^t:m_{ret} \to c:r$
  + 同样地，这里没有从x到m_this的CSPFG边，否则不精确

**Main Algorithm**
```
Solve(S)
  WL = []
  PFG = {}
  S = {}, RM = {}, CG = {}
  AddReachable([]:m_entry)

  while WL is not empty do
    remove (n, pts) from WL
    delta = pts - pt(n)
    Propagate(n,delta)
    if n represent a variable c:x then
      foreach c':o_i in delta do
        foreach x.f = y in S do
          AddEdge(c:y, c':o_i.f)
        foreach y = x.f in S do
          AddEdge(c':o_i.f, c:y)
        ProcessCall(c:x, c':o_i)
```

**AddReachable**
```
AddReachable(c:m)
  if c:m not in RM then
    add c:m to RM
    S ∪= S_m
    foreach i: x = new T() in S_m do
      add (c:x, {c:o_i}) to WL
    foreach i: x = y in S_m do
      AddEdge(c:y, c:x)
```

**ProcessCall**
```
ProcessCall(c:x, c':o_i)
  foreach l: r = x.k(a1,...,an) in S do
    m = Dispatch(o_i, k)
    c^t = Select(c,l,c':o_i)
    add (c^t:m_this, {c':o_i}) to WL
    if c:l->c^t:m not in CG then
      add c:l->c^t:m to CG
      AddReachable(c^t:m)
      foreach parameter p_i of m do
        AddEdge(c:a_i, c^t:p_i)
      AddEdge(c^t:m_ret, c:r)
```

AddEdge和Propagate和CI的一样。

只是在CI算法的基础上在指针和对象之前加上了上下文的修饰，并在调用语句的处理当中增加了新上下文的生成。

其中，需要注意一下的是我们设置入口方法的上下文为空，因为一般情况下程序的入口方法只会被操作系统调用一次，因而不需要用上下文加以区分。

### 上下文敏感的各种变体
下面是Select函数的内容。CI其实就是Select函数返回值为空的特殊情况。而不同的敏感策略使用传入的三个值的子集，一般不会全部使用。

+ 调用点敏感：
  + 把调用点append到当前的上下文中
  + 也叫call-string sensitivity，或者k-CFA（k控制流分析），k-调用点敏感
  + 如果递归则上下文无穷大了，所以用k进行深度限制
    + 实践中的k通常是小于等于3的很小值
    + 也有可能对不同的上下文k不一样，方法上下文k=2，堆上下文k=1
+ 对象敏感：
  + 用一串抽象对象作为上下文
  + 本质上是分配点敏感
  + 与调用点敏感的效果各有千秋
    + 理论上精度是不可比的
    + OO语言的实践中，对象敏感比调用点敏感要好一点
+ 类型敏感
  + 上下文是一串类型
  + 用接收对象的分配点所在的类，而不是对象本身的类
  + 是对对象敏感的一种更粗糙的抽象，用接收对象分配点所在的类代替了接收对象作为上下文
  + 和对象敏感相比，效果比它差，毕竟是粗糙抽象，牺牲精度换时间

通常而言在实践中：
+ 精度：对象>类型>调用点
+ 效率：类型>对象>调用点

# Lec 13：Static Analysis for Security
### 信息流安全
如果系统能在存在对手（攻击者）的情况下达成原本的目的，称其为安全的。

**访问控制**是指对于特定的信息检查请求访问该信息的程序是否具有相应的权限或者是否得到了相应的许可。只关心访问这个动作，后续的信息安全只能选择信任得到授权的访问客体。

**信息流安全**是指通过追踪信息是如何在程序中流动的方式，来确保程序安全地处理了它所获得的信息。端到端地，关心数据如何传播。

访问控制和信息流安全是一个安全系统都需要的东西。

可以将程序中的变量分为不同的安全等级，并制定一些信息流政策来规范信息流动的方向。可以用格来描述这个安全等级。最基本的是H、L两级模型。要求：
+ 高级的信息不能对低级的信息造成任何影响
+ 只看到低级的变量，任何人不应该获得任何高级变量的信息

### 机密性和完整性
+ 机密性（Confidentiality） 指的是阻止机密的信息泄漏
  + 信息只能从低机密性流动到高机密性
  + 读保护
+ 完整性（Integrity） 指的是阻止不信任的信息污染受信任的关键信息
  + 信息只能从高完整性流动到低完整性
  + 写保护
  + 例子：注入攻击

****广义的完整性****是指保证数据
+ 正确性（Correctness）：受信任的关键数据不应当被不受信任的数据所污染
+ 完全性（Completeness）：一个数据库系统应当完全地储存所有的数据，不应该有数据丢失
+ 一致性（Consistency）：一个文件传输系统应该保证在文件内容在收发两端相同

### 显式流和隐蔽信道
+ 信息通过直接赋值、拷贝的方式流动称为**显式流**。
+ 信息通过影响控制流的方式被泄露，称为**隐式流**。

如果指示了某种信息的方式本意并非传递数据，则称为**隐蔽信道**，包含：
+ 隐式流
+ 终止信道：通过程序是否终止泄露信息
+ 时间信道：通过程序执行时间泄露信息
+ 异常：通过程序是否抛出异常泄露信息

显式流泄露更多的信息，且隐蔽信道十分难以检测，所以下面注重研究预防显式流。

### 污点分析
污点数据：关心的敏感数据，我们会给这些数据加标签。污点分析需要研究污点数据是如何流动的。
+ 污点数据从源头source产生，实践中一般是一些方法的返回值
+ 我们不希望它们流动到水槽sink中，实践中一般是一些敏感的方法调用

污点分析可以用来分析机密性和完整性有没有被破坏。（分析数据流动方向）

可以用指针分析来实现污点分析。
+ 污点数据就是人造的对象，和正常的对象一起流动
  + （并不是把一个方法的返回值直接标记为污点数据，而是在保留返回值的同时凭空手动创造一个污点数据）
+ 源头source作为污点对象的分配点
+ 算法的输入是源头和水槽，输出是污点流(i,j,k)，说明从哪里(i)产生的污点流入了哪一个水槽(j)的第几个参数(k)

**规则**（除了处理source和sink的，别的和指针分析一样）：
+ l:r = x.k(a1,...,an)
  + Source:
    + $l\to m\in CG, m\in Source$ ---> $t_l\in pt(r)$
  + Sink:
    + $l\to m \in CG, (m,i)\in Sinks, t_j\in pt(a_i)$ ---> $(j,i,l)\in TaintFlows$ 

# Lec 14：Datalog-Based Program Analysis
### Motivation
+ 命令式语言：给出一个目标的实现。怎么做。
  + 实现指针分析的过程中要考虑非常多的细节
    + 如何实现WL，每次取出哪一项处理
    + 如何实现指向集
    + 如何联系指针和PFG结点
    + ……
+ 申述式语言：给出一个目标的规约。做什么。
  + 可以实现一个简洁的、可读性强的（逻辑性）、容易实现的指针分析。

### Datalog介绍
Datalog是Prolog的子集，现有很多应用：
+ 程序分析
+ 申述式网络编程
+ 大数据、云计算

没有副作用、没有控制流、没有函数、非图灵完备。

+ 谓词predicates：本质上就是一个表格。
+ 事实fact：断言特定的一行属于某个表格。
+ 关系型原子：datalog中返回值为True或者False的表达式
  + P(x1,x2,...,xn)
  + P是谓词
  + xi是实参arguments或者项terms：可以是变量或者常量
    + Age(person, age)
    + Age("drf", 21)
  + 如果P中含有(x1,...,xn)描述的这一行，则这个“关系型原子”的值为True
+ 算术原子
  + e.g. age>=18
+ 规则：
  + H <- B1,B2,...,Bn
  + H是head，是结果，是一个原子
  + Bi是body，是前提，是一个原子或者原子的否定
  + 所有body都是真的，则head就是真的
  + 例子：Adult(person) <- Age(person, age), age >= 18

**Datalog的解释器如何解释一个规则？** Datalog 会考虑子目标中变量的所有可能的组合，如果存在某个组合使得所有的子目标都为真，那么带有相应变量的头部原子也为真。头部谓词会包含所有为真的原子的项，作为该谓词的事实存下来。

可以认为，Datalog程序 = 试试Fact + 规则rules

**原始的数据从哪里来？** 
+ EDB外部数据库，作为输入，里面的关系不能修改
  + 不能修改 -> 任何规则语句的头部必须是IDB
+ IDB内部数据库，视为输出，其中的关系都是通过推导得到

逻辑用语：
+ 合取：逗号","
+ 析取：
  + 分号";"
  + 写两个规则，任何一个成立都可以推导出
  + e.g. H <- A, (B;C)
+ 否定：感叹号"!"

IDB可以从自己的元素推导得到新的元素，即允许递归。图的连接性问题（传递闭包）就可以通过递归解决。

**定义：一个规则是安全的** ，如果
+ 每个变量都至少在一个非否定原子中出现过（防止无限的取值，使得推导得到的IDB包含无限行）
+ 原子的递归和否定必须分开（防止矛盾出现，逻辑推理无法收敛）

Datalog语言本身是一个规约所以比较简单，实现这个语言的称为Datalog引擎，本质上还是命令式的，只是这一层抽象由引擎完成了。
+ 不同引擎有不同的特性。
+ 引擎会根据输入EDB和规则进行推导，直到没有新的事实可以被推导出来。
+ Datalog程序具有单调性
  + 因为它只会推导新的事实，而无法删除已有的事实。
  + 由于单调有界性，Datalog会停止，从而非图灵完备。

### 使用Datalog进行指针分析
+ EDB：从程序语法上提取的指针相关信息
  + New(x, o)
  + Assign(x, y)
  + Store(x, f, y)
  + Load(y, x, f)
  + 调用相关
    + VCall(l, x, k)
    + Dispatch(o, k, m)
    + ThisVar(m, this)
    + Argument(l, i, ai)
    + Parameter(m, i, pi)
    + MethodReturn(m, ret)
    + Callreturn(l, r)
+ IDB：指针分析结果
  + VarPointsTo(v, o)
  + FieldPointsTo(oi, f, oj)
  + Reachable(m)
  + CallGraph(l, m)
+ 规则就是指针分析的规则。


```
Reachable(m) <-
    EntryMethod(m).

VarPointsTo(x, o) <-
    Reachable(m),
    New(x, o, m).

VarPointsTo(x, o) <-
    Assign(x, y),
    VarPointsTo(y, o).

FieldPointsTo(oi, f, oj) <-
    Store(x, f, y),
    VarPointsTo(x, oi),
    VarPointsTo(y, oj).

VarPointsTo(y, oj) <-
    Load(y, x, f),
    VarPointsTo(x, oi),
    FieldPointsTo(oi, f, oj).

VarPointsTo(this, o),
Reachable(m),
CallGraph(l, m) <-
    VCall(l, x, k),
    VarPointsTo(x, o),
    Dispatch(o, k, m),
    ThisVar(m, this).

VarPointsTo(pi, o) <-
    CallGraph(l, m),
    Argument(l, i, ai),
    Parameter(m, i, pi),
    VarPointsTo(ai, o).

VarPointsTo(r, o) <-
    CallGraph(l, m),
    MethodReturn(m, ret),
    VarPointsTo(ret, o),
    CallReturn(l, r).
```

### 使用Datalog进行污点分析
在指针分析之外，有：
+ EDB：
  + Source(m)
  + Sink(m, i)
  + Taint(l, t)
+ IDB：
  + TaintFlow(sr, sn, i)

```
VarPointsTo(r, t) <-
  CallGraph(l, m),
  Source(m),
  CallReturn(l, r),
  Taint(l, t).

TaintFlow(j, l, i) <-
  CallGraph(l, m),
  Sink(m, i),
  Argument(l, i, ai),
  VarPointsTo(ai, t),
  Taint(j, t).
```

+ 优势：
  + 简洁易读
  + 实现简单
  + 受益于现有的Datalog引擎优化
+ 劣势：
  + 表达能力受限
  + 黑盒，有些东西用户不可控

# Lec 15：CFL-Reachability and IFDS
### 可行路径和可实现路径
一个方法的控制流图可能会非常巨大，其中有一些path可能根本不会被执行。对于确定的输入，只会有一条路径被执行；如果输入不同，会有一个子集路径可能被执行；但是存在不可能被执行的路径。

+ **可行路径 Feasible Path**：某个特定的输入下会被执行的路径。
+ **不可行路径 Infeasible Path**：任何输入下都不会被执行的路径。
>但是，在静态分析的阶段，给定一个路径，判断它是否可行在整体上是不现实的，因为静态分析阶段我们并不知道这个程序的具体输入是什么，而一个路径是否会被执行又是与具体的输入息息相关的。

+ **可实现路径 Realizable Path**：调用和返回相对应的路径。
  + 可能不会被执行，但是**不可实现路径**是绝对不可能被执行的。
  + 目标是找到所有可实现路径，然后只分析它们，相当于排除了不可实现路径。

### CFL-可达性
**CFL-可达性**：为一张有向图中的每条边打上标签，称结点B从结点A CFL可达，如果存在从A到B的路径，该路径上每条边的标签组成了某个特定的上下文无关语言的合法字符串。

> 上下文无关语言有其上下文无关的文法：
> + 形式文法，其中，每一个推导式都形如$S\to \alpha$
> + 其中，$S$是单个非终结符，规定唯一的起始符号
> + $\alpha$可以是终结符与/或非终结符形成的字符串，也可以是空字符串。

可以定义部分平衡括号问题：
+ 每个右括号)i都有一个左括号(i与之对应，反之没有
+ 调用边对应左括号，返回边对应右括号
+ 其他所有边对应e

一个路径是可实现的，当且仅当这个路径上的标记所形成的字符串在语言$L(realizable)$中，其中：
+ $realizable$ 
  + $\to matched \quad realizable$
  + $\to (_i \quad realizable$
  + $\to \epsilon$
+ $matched$
  + $\to (_i \quad matched \quad )_i$ 
  + $\to e$
  + $\to \epsilon$
  + $\to matched \quad matched$

### IFDS概述
“通过图的可达性进行过程间数据流分析的方法。”

IFDS (Interprocedural, Finite, Distributive, Subset Problem)。

IFDS为数据流分析提供了一种可实现全路汇集（MRP，Meet-over-all-Realizable-Path）的解决方案。从定义可以看出，MRP是MOP的子集，且MRP更准确：
+ may analysis时，结果比MOP少
+ must analysis时，结果比MOP多
+ 这个结论是由函数的分配性得到的，相当于函数额外作用在了MOP-MRP这个集合上

IFDS分析框架：
+ 给定一个程序P和数据流分析问题Q
+ 为P建立一个**超图G*=(N*,E*)**，并根据Q定义G*中边的流函数
+ 通过将流函数转化为**代表关系**，基于G*为P建立一个**分解超图G#**
+ Q可以被当作G#上的可达性问题来解决，具体地，通过在G#上运行制表算法解决
+ 令$n_i$是某个程序点，数据流因素/数据流值$d\in MRP[n_i]$当且仅当G#中存在一条从$(s_{main}, 0)$到$(n_i, d)$的可实现路径。

概念解析：
+ 超图：一系列控制流图的集合，每个过程有一个控制流图
  + 每个控制流图$G_p$有唯一的入口$s_p$和出口$e_p$
  + 在每个控制流图中用调用结点$Call_p$和返回结点$Ret_p$来表示对过程p的调用
  + 除了过程内部的控制流边，还有：
    + 过程内：从调用结点到返回结点的边，call-to-return
    + 过程间：从调用结点到被调用程序的入口，call-to-start
    + 过程间：从被调用程序的出口到返回结点，exit-to-return
  + （和控制流图非常相似，只是把调用点分为了“调用结点”“返回结点”两部分）
+ 流函数：通过“可能未初始化变量”问题来解释
  + lambda表达式：$(\lambda e_{para}.e_{body})(e_{arg})$
  + call-to-start边：调用边将未初始化的实参改名问形参
  + `a=a-g`语句根据安全近似，只要右值a或g之一没有初始化，就需要在未初始化集合中加入左值a
  + call-to-return边：
    + 传递本地值提升效率
    + 体现函数的副作用，例如减去调用的方法体内部的变量，这个变量的定义与否完全由被调用方法决定。如果不删除，则合并后肯定存在于集合中，假阳性
  + exit-to-return边：
    + 减去方法体内部的消亡的本地变量
    + 传递返回值
+ 分解超图G#：
  + 代表关系：每个流函数可以被表示成有2(|D|+1)个结点的二部图
    + 其中D是数据流fact的有限集合
    + +1是因为有一个额外的“0”结点
    + 二部图的边体现出前后的依赖关系：
      + 有我没他
      + 有我才有他
      + ……
  + 构建分解超图就是将这个以上的二部图首尾相连
  + **粘边**：0 --> 0的边。
    + IFDS 中分解超图上的粘边是为了表达出流函数的复合运算
    + 在IFDS中，通过判断是否有一个从开头到某程序点p的路径，来判断可达性
    + “凭空产生数据流值x”这个概念在二部图中就是 0 --> x的一条边，如果没有从头开始的 0 --> 0，那么x不会从头到尾有一条路径，出现错误FN
  + 构建完超图之后，数据的流动就被展示出来了。但是此时可实现的和不可实现的路径同时存在于超图中。需要制表算法。
+ 制表算法：
  + 复杂度$O(|E||D|^3)$，边数和数据流值数量
  + 细节不重要，关注核心
    + 发现一个方法可达之后，让它的开始结点自引，表示已经被分析过，后续就不需要分析这个方法内部的可达性了
    + 在处理一个方法的结束结点的时候进行调用-返回的匹配
    + 从call到对应ret的总结边，表示通过方法调用之后的可达性

### 理解IFDS的分配性
可以用IFDS的条件：**分配性**。给定一个语句，如果需要超过一个输入才能得到对应的输出，则不满足分配性。在 IFDS 能够处理的问题中，每个数据流因素及其传播都应当可以被独立地处理，并且这样做并不会影响最终结果的正确性，否则就无法使用 IFDS 来解决。

因此常量传播（常量个数有限）也不行，因为处理不了a=x+y，除非每一个操作都是线性变换x=y+3。

指针分析也不行，这是因为流函数它只看自己这一步的信息，没有别的信息。对于指针分析来说，别名问题它无法处理。

# Lec 16：Soundiness
### Soundness and Soundiness
现实世界中真正的完全分析是很难的。学术界和工业界几乎绝大多数问题都是不完全的，或者被迫做出不完全的选择。

这是因为编程语言可能会有一些对于静态分析来说“难的语言特性”：对这些特性进行激进的保守处理（即完全的过近似）可能会使分析过于不精确而无法扩展（scale），从而使分析变得无用。

+ Java
  + 反射
  + 原生代码
  + 动态类加载
+ JS
  + 检测（eval）
  + 文档对象模型
+ C、C++
  + 指针运算
  + 函数运算

一般的论文如何处理：
+ 一般来说，声称自己完全的静态分析，在它的实现中只是尽可能有一个完全的核心（sound core）
  + 对大部分特性过近似
  + 对部分难的特性欠近似
+ 在论文的一些实现或者评估（Evaluation）的部分中，对难的语言特性的处理通常被省略或仅以一种比较水的方式提及一下

但对于一些特定的难的语言特性（比如说Java反射）没有合适的处理的话，对于分析的结果会有举足轻重的影响。并且在论文中声称完全性可能会误导读者。因此提出了“近似完全性”soundiness。
+ sound：完全的
+ soundy：致力于完全，但是合理地unsound处理一些难的特性
+ unsound：有意放弃完全性，为了更加的效率、精度等

### Java反射
它允许正在执行的Java程序检查或“自省”自身，并操纵程序的内部属性。

Java反射为这些程序的内部属性（类、域等）提供了一些访问和使用的接口，称为 元对象（Metaobject） ，我们可以借助反射在运行时访问到编译时的程序的内部属性，像编译时写代码一样，在运行时操作这些内部属性。

引入Java反射机制是为了在大型程序开发的过程中降低程序的耦合性，使得程序易于拓展、修改和维护。

反射更体现出一种**运行时**的状态。反射机制通过字符串来获取元对象，如果我们能够分析出这个字符串是啥，就可以根据反射函数的语义去推导出它获取的是哪一个类、方法或者字段的元对象了。

解决方法：
+ 字符串常量传播+指针分析
  + 问题：字符串常量不一定是hardcode的，有可能从配置文件、控制台等地方传入，甚至是加密的，无法分析到
+ 类型接口 + 字符串分析 + 指针分析
  + intuition：无法静态直到字符串的内容，那就在使用的时候进行推断
+ 用动态分析辅助
  + 使用一些动态测试样例去帮助确定目标方法，然后使用动态分析的结果来辅助静态分析
  + 很难sound，样例有限


### 原生代码
Java是一个虚拟机语言，是运行在JVM上的，而JVM是用C/C++写的，因为毕竟需要和操作系统打交道，以及更底层的各种设备的访问和驱动。

> Java原生接口（Java Native Interface, JNI） 是JVM的一个功能模块，允许Java代码和原生代码（C/C++）之间的交互。
+ 提供平台支持的特性（与OS打交道，如print）
+ 调用现成的C、C++库

实践中的处理方法一般是对原生代码进行手工模拟，编写等价的Java代码。并且在手动实现原生代码的时候，可以针对我们要研究的问题进行一些抽象，从而在不影响问题研究的前提下简化实现。